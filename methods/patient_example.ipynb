{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/walterdempsey/Box/MD2K Processed Data/smoking-lvm-cleaned-data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "os.getcwd()\n",
    "dir = \"/Users/walterdempsey/Box/MD2K Processed Data/smoking-lvm-cleaned-data/\"\n",
    "os.chdir(dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['8to9', '9to10', '10to11', '11to12','12to13','13to14','14to15','15to16','16to17','17to18','18to19','19to20']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "eod_original_cloud_ids = [201, 203, 206, 221, 229] \n",
    "eod_ema = pd.read_csv(dir + 'eod-ema.csv')\n",
    "eod_ema = eod_ema.drop(['offset'], axis = 1)\n",
    "eod_ema_alternative = pd.read_csv(dir + 'eod-ema-alternative.csv')\n",
    "eod_ema_backup = pd.read_csv(dir + 'eod-ema-backup.csv')\n",
    "temp_eod_original = eod_ema[eod_ema['participant_id'].isin(eod_original_cloud_ids)]\n",
    "temp_eod_alt = eod_ema_alternative[~eod_ema_alternative['participant_id'].isin(eod_original_cloud_ids)]\n",
    "\n",
    "eod_complete = pd.concat([temp_eod_original, temp_eod_alt, eod_ema_backup])\n",
    "\n",
    "puffmarker_original_cloud_ids = [201, 203, 206, 210, 221, 229] \n",
    "puffmarker = pd.read_csv(dir + 'puff-probability.csv')\n",
    "puffmarker = puffmarker.drop(['offset'], axis = 1)\n",
    "puffmarker_alternative = pd.read_csv('puff-probability-alternative.csv')\n",
    "puffmarker_backup = pd.read_csv('puff-probability-backup.csv')\n",
    "\n",
    "temp_puffmarker_original = puffmarker[puffmarker['participant_id'].isin(puffmarker_original_cloud_ids)]\n",
    "temp_puffmarker_alt = puffmarker_alternative[~puffmarker_alternative['participant_id'].isin(puffmarker_original_cloud_ids)]\n",
    "\n",
    "puffmarker_complete = pd.concat([temp_puffmarker_original, temp_puffmarker_alt, puffmarker_backup])\n",
    "\n",
    "participant_dates = pd.read_csv(dir + 'participant-dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a list of id + dates for eod\n",
    "# Use to look \n",
    "eod_dates = []\n",
    "for irow in range(0,eod_complete.shape[0]):\n",
    "    row = eod_complete.iloc[irow]\n",
    "    if row['participant_id'] == 252 or row['participant_id'] == 253:\n",
    "        continue\n",
    "    quit_iloc = np.where(participant_dates['participant'] == row['participant_id'])\n",
    "    quit_row = participant_dates.iloc[quit_iloc[0][0]]\n",
    "    quit_time = datetime.datetime.strptime(quit_row['quit_date'], '%m/%d/%y')\n",
    "    if row['status'] == \"MISSED\":\n",
    "        continue\n",
    "    try:\n",
    "        time = datetime.datetime.strptime(row['date'], '%m/%d/%Y %H:%M')\n",
    "    except:\n",
    "        time = datetime.datetime.strptime(row['date'], '%Y-%m-%d %H:%M:%S')\n",
    "    #print row['participant_id'], time\n",
    "    #print quit_row['participant'], quit_time\n",
    "    temp_diff = time - quit_time\n",
    "    if time.hour  == 0 or time.hour == 1:\n",
    "        date = np.array([row['participant_id'], temp_diff.days-1])\n",
    "        date = np.append(date, np.sum(np.array(row[keys])))\n",
    "    else:\n",
    "        date = np.array([row['participant_id'], temp_diff.days])\n",
    "        date = np.append(date, np.sum(np.array(row[keys])))\n",
    "    #print date\n",
    "    eod_dates.append(date)\n",
    "    \n",
    "eod_dates = np.asarray(eod_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eod_survival = []\n",
    "for id in set(eod_dates[:,0]):\n",
    "    subset = eod_dates[eod_dates[:,0] == id,:]\n",
    "    if any(subset[:,1] > 0):\n",
    "        subset = subset[subset[:,1] > 0,:]\n",
    "        nonzero_iloc = np.where(subset[:,2] > 0)[0]\n",
    "        zero_iloc = np.where(subset[:,2] == 0)[0]\n",
    "        if len(nonzero_iloc) == 0:\n",
    "            if len(zero_iloc) != 0:\n",
    "                temp = np.append(subset[np.max(zero_iloc),0:2], 0)\n",
    "        else:\n",
    "            temp = np.append(subset[np.max(nonzero_iloc), 0:2], 1)\n",
    "        eod_survival.append(temp)\n",
    "\n",
    "eod_survival = np.asarray(eod_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data for contingent EMA\n",
    "ec_original_cloud_ids = [201, 221, 229] \n",
    "contingent_ema = pd.read_csv(dir + 'eventcontingent-ema.csv')\n",
    "contingent_ema = contingent_ema.drop(['offset'], axis = 1)\n",
    "contingent_ema_alternative = pd.read_csv(dir + 'eventcontingent-ema-alternative.csv')\n",
    "contingent_ema_backup = pd.read_csv(dir + 'eventcontingent-ema-backup.csv')\n",
    "\n",
    "temp_contingent_original = contingent_ema[contingent_ema['participant_id'].isin(ec_original_cloud_ids)]\n",
    "temp_contingent_alt = contingent_ema_alternative[~contingent_ema_alternative['participant_id'].isin(ec_original_cloud_ids)]\n",
    "\n",
    "contingent_complete = pd.concat([temp_contingent_original, temp_contingent_alt, contingent_ema_backup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to look \n",
    "ec_dates = []\n",
    "for irow in range(0,contingent_complete.shape[0]):\n",
    "    row = contingent_complete.iloc[irow]\n",
    "    quit_iloc = np.where(participant_dates['participant'] == row['participant_id'])\n",
    "    quit_row = participant_dates.iloc[quit_iloc[0][0]]\n",
    "    quit_time = datetime.datetime.strptime(quit_row['quit_date'], '%m/%d/%y')\n",
    "    if row['status'] == \"MISSED\":\n",
    "        continue\n",
    "    try:\n",
    "        time = datetime.datetime.strptime(row['date'], '%m/%d/%y %H:%M')\n",
    "    except:\n",
    "        time = datetime.datetime.strptime(row['date'], '%Y-%m-%d %H:%M:%S')\n",
    "    #print row['participant_id'], time\n",
    "    #print quit_row['participant'], quit_time\n",
    "    temp_diff = time - quit_time\n",
    "    if row['smoke'] == 'Yes':\n",
    "        if time.hour  == 0 or time.hour == 1:\n",
    "            date = np.array([row['participant_id'], temp_diff.days-1])\n",
    "        else:\n",
    "            date = np.array([row['participant_id'], temp_diff.days])\n",
    "    #print date, time\n",
    "        ec_dates.append(date)\n",
    "    \n",
    "ec_dates = np.asarray(ec_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_survival = []\n",
    "for id in set(ec_dates[:,0]):\n",
    "    subset = ec_dates[ec_dates[:,0] == id,:]\n",
    "    if any(subset[:,1] > 0):\n",
    "        subset = subset[subset[:,1] > 0,:]\n",
    "        temp = [id, np.max(subset[:,1])]\n",
    "        ec_survival.append(temp)\n",
    "\n",
    "ec_survival = np.asarray(ec_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data for random EMA\n",
    "random_original_cloud_ids = [201, 203, 206, 210, 221, 226, 229] \n",
    "random_ema = pd.read_csv(dir + 'random-ema.csv')\n",
    "random_ema = random_ema.drop(['offset'], axis = 1)\n",
    "\n",
    "random_ema_alternative = pd.read_csv(dir + 'random-ema-alternative.csv')\n",
    "random_ema_backup = pd.read_csv(dir + 'random-ema-backup.csv')\n",
    "\n",
    "temp_random_original = random_ema[random_ema['participant_id'].isin(random_original_cloud_ids)]\n",
    "temp_random_alt = random_ema_alternative[~random_ema_alternative['participant_id'].isin(random_original_cloud_ids)]\n",
    "\n",
    "random_complete = pd.concat([temp_random_original, temp_random_alt, random_ema_backup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to look \n",
    "random_dates = []\n",
    "for irow in range(0,random_complete.shape[0]):\n",
    "    row = random_complete.iloc[irow]\n",
    "    quit_iloc = np.where(participant_dates['participant'] == row['participant_id'])\n",
    "    quit_row = participant_dates.iloc[quit_iloc[0][0]]\n",
    "    quit_time = datetime.datetime.strptime(quit_row['quit_date'], '%m/%d/%y')\n",
    "    if row['status'] == \"MISSED\":\n",
    "        continue\n",
    "    try:\n",
    "        time = datetime.datetime.strptime(row['date'], '%m/%d/%y %H:%M')\n",
    "    except:\n",
    "        time = datetime.datetime.strptime(row['date'], '%Y-%m-%d %H:%M:%S')\n",
    "    #print row['participant_id'], time\n",
    "    #print quit_row['participant'], quit_time\n",
    "    temp_diff = time - quit_time\n",
    "    if time.hour  == 0 or time.hour == 1:\n",
    "        date = np.array([row['participant_id'], temp_diff.days-1])\n",
    "        if row['smoke'] == 'Yes':\n",
    "            date = np.append(date, [1])\n",
    "            random_dates.append(date)\n",
    "        if row['smoke'] == 'No':\n",
    "            date = np.append(date, [0])\n",
    "            random_dates.append(date)\n",
    "    else:\n",
    "        date = np.array([row['participant_id'], temp_diff.days])\n",
    "        if row['smoke'] == 'Yes':\n",
    "            date = np.append(date, 1)\n",
    "            random_dates.append(date)\n",
    "        if row['smoke'] == 'No':\n",
    "            date = np.append(date, 0)\n",
    "            random_dates.append(date)\n",
    "\n",
    "random_dates = np.asarray(random_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_survival = []\n",
    "for id in set(random_dates[:,0]):\n",
    "    subset = random_dates[random_dates[:,0] == id,:]\n",
    "    if any(subset[:,1] > 0):\n",
    "        subset = subset[subset[:,1] > 0,:]\n",
    "        nonzero_iloc = np.where(subset[:,2] == 1)[0]\n",
    "        zero_iloc = np.where(subset[:,2] == 0)[0]\n",
    "        if len(nonzero_iloc) == 0:\n",
    "            if len(zero_iloc) != 0:\n",
    "                temp = np.append(subset[np.max(zero_iloc),0:2], 0)\n",
    "        else:\n",
    "            temp = np.append(subset[np.max(nonzero_iloc), 0:2], 1)\n",
    "        random_survival.append(temp)\n",
    "\n",
    "random_survival = np.asarray(random_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[202,   7,   1],\n",
       "       [203,  13,   0],\n",
       "       [205,   8,   1],\n",
       "       [206,   9,   0],\n",
       "       [207,   1,   1],\n",
       "       [208,   3,   1],\n",
       "       [211,   2,   1],\n",
       "       [212,   6,   1],\n",
       "       [213,   1,   0],\n",
       "       [214,   2,   1],\n",
       "       [215,  10,   1],\n",
       "       [216,   9,   1],\n",
       "       [217,   3,   1],\n",
       "       [218,   1,   1],\n",
       "       [219,  10,   1],\n",
       "       [222,   1,   1],\n",
       "       [223,  11,   0],\n",
       "       [224,   9,   1],\n",
       "       [225,   9,   1],\n",
       "       [226,   5,   1],\n",
       "       [227,  10,   1],\n",
       "       [228,   8,   1],\n",
       "       [229,   2,   1],\n",
       "       [230,   9,   1],\n",
       "       [231,   1,   1],\n",
       "       [233,   6,   1],\n",
       "       [234,   1,   0],\n",
       "       [235,   4,   0],\n",
       "       [238,   9,   1],\n",
       "       [240,  10,   1],\n",
       "       [241,   1,   1],\n",
       "       [242,   8,   1],\n",
       "       [243,   5,   0],\n",
       "       [245,   4,   1],\n",
       "       [247,   9,   1],\n",
       "       [248,  10,   0],\n",
       "       [249,   1,   1],\n",
       "       [250,  10,   0],\n",
       "       [252,   9,   1],\n",
       "       [253,  11,   1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ema_survival = []\n",
    "\n",
    "for id in set(random_survival[:,0]) | set(ec_survival[:,0]) | set(eod_survival[:,0]):\n",
    "    temp = np.array([id])\n",
    "    random_subset = random_survival[random_survival[:,0] == id,:]\n",
    "    if not len(random_subset) == 0:\n",
    "        temp = np.append(temp, random_subset[0][1:3])\n",
    "    else:\n",
    "        temp = np.append(temp, [-1,-1])\n",
    "    ec_subset = ec_survival[ec_survival[:,0] == id,:]\n",
    "    if not len(ec_subset) == 0:\n",
    "        ec_day = ec_subset[0][1]\n",
    "        if temp[1] > ec_day or temp[1] == -1:\n",
    "            temp[1:3] = [ec_day,1]\n",
    "    eod_subset = eod_survival[eod_survival[:,0] == id, :]\n",
    "    if not len(eod_subset) == 0:\n",
    "        if eod_subset[0][1] < temp[1] and eod_subset[0][2] == 1:\n",
    "            temp[1:3] = eod_subset[0][1:3]\n",
    "        elif eod_subset[0][1] > temp[1] and eod_subset[0][2] == 0 and temp[2] == 0:\n",
    "            temp[1:3] = eod_subset[0][1:3]\n",
    "    all_ema_survival.append(temp)\n",
    "    \n",
    "all_ema_survival = np.asarray(all_ema_survival)\n",
    "\n",
    "all_ema_survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "puffmarker_episode_original_cloud_ids = [201, 203, 206, 210, 229] \n",
    "puffmarker_episode = pd.read_csv(dir + 'puff-episode.csv')\n",
    "puffmarker_episode = puffmarker_episode.drop(['offset'], axis = 1)\n",
    "puffmarker_episode_alternative = pd.read_csv('puff-episode-alternative.csv')\n",
    "puffmarker_episode_backup = pd.read_csv('puff-episode-backup.csv')\n",
    "\n",
    "temp_puffmarker_episode_original = puffmarker_episode[puffmarker_episode['participant_id'].isin(puffmarker_episode_original_cloud_ids)]\n",
    "temp_puffmarker_episode_alt = puffmarker_episode_alternative[~puffmarker_episode_alternative['participant_id'].isin(puffmarker_episode_original_cloud_ids)]\n",
    "\n",
    "puffmarker_episode_complete = pd.concat([temp_puffmarker_episode_original, temp_puffmarker_episode_alt, puffmarker_episode_backup])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quit date is 2018-12-03 00:00:00\n",
      "Current date is 2018-12-12 00:00:00\n",
      "status                      COMPLETED\n",
      "8to9                                1\n",
      "9to10                               0\n",
      "10to11                              0\n",
      "11to12                              1\n",
      "12to13                              1\n",
      "13to14                              0\n",
      "14to15                              1\n",
      "15to16                              0\n",
      "16to17                              0\n",
      "17to18                              0\n",
      "18to19                              0\n",
      "19to20                              0\n",
      "participant_id                    252\n",
      "timestamp               1544668414661\n",
      "date              2018-12-12 20:33:34\n",
      "hour                               20\n",
      "minute                             33\n",
      "day_of_week                 Wednesday\n",
      "Name: 320, dtype: object\n",
      "Onto RANDOM EMA\n",
      "Yes 1 - 19 Minutes 2018-12-12 07:16:10\n",
      "No None 2018-12-12 12:05:20\n",
      "No None 2018-12-12 15:48:05\n",
      "Onto Event Contingent EMA\n",
      "Yes 15 to 30 minutes 2018-12-12 11:35:53\n",
      "Onto puffMarker episode detection\n",
      "2018-12-12 11:12:14\n",
      "Onto puffMarker puff detection\n",
      "2018-12-12 07:07:20\n",
      "2018-12-12 07:11:27\n",
      "2018-12-12 07:11:55\n",
      "2018-12-12 07:12:21\n",
      "2018-12-12 07:14:12\n",
      "2018-12-12 07:24:30\n",
      "2018-12-12 07:36:38\n",
      "2018-12-12 07:43:57\n",
      "2018-12-12 08:05:10\n",
      "2018-12-12 08:06:41\n",
      "2018-12-12 08:11:41\n",
      "2018-12-12 08:17:54\n",
      "2018-12-12 08:35:04\n",
      "2018-12-12 08:36:14\n",
      "2018-12-12 08:37:34\n",
      "2018-12-12 08:39:30\n",
      "2018-12-12 08:46:11\n",
      "2018-12-12 08:48:36\n",
      "2018-12-12 08:55:29\n",
      "2018-12-12 08:56:17\n",
      "2018-12-12 09:28:37\n",
      "2018-12-12 10:03:25\n",
      "2018-12-12 10:19:30\n",
      "2018-12-12 10:39:48\n",
      "2018-12-12 10:52:47\n",
      "2018-12-12 11:01:17\n",
      "2018-12-12 11:12:14\n",
      "2018-12-12 11:12:36\n",
      "2018-12-12 11:13:11\n",
      "2018-12-12 11:13:30\n",
      "2018-12-12 11:13:36\n",
      "2018-12-12 11:17:48\n",
      "2018-12-12 11:18:01\n",
      "2018-12-12 11:21:07\n",
      "2018-12-12 11:28:14\n",
      "2018-12-12 11:32:53\n",
      "2018-12-12 11:59:38\n",
      "2018-12-12 12:09:10\n",
      "2018-12-12 12:22:55\n",
      "2018-12-12 12:35:58\n",
      "2018-12-12 12:50:01\n",
      "2018-12-12 12:57:16\n",
      "2018-12-12 12:58:58\n",
      "2018-12-12 13:07:09\n",
      "2018-12-12 13:12:21\n",
      "2018-12-12 13:14:08\n",
      "2018-12-12 13:35:08\n",
      "2018-12-12 13:48:08\n",
      "2018-12-12 14:26:38\n",
      "2018-12-12 14:35:16\n",
      "2018-12-12 14:37:25\n",
      "2018-12-12 14:40:38\n",
      "2018-12-12 14:54:03\n",
      "2018-12-12 15:00:31\n",
      "2018-12-12 15:01:29\n",
      "2018-12-12 15:13:32\n",
      "2018-12-12 15:33:31\n",
      "2018-12-12 16:15:23\n",
      "2018-12-12 16:19:54\n",
      "2018-12-12 16:29:06\n",
      "2018-12-12 16:35:10\n",
      "2018-12-12 16:46:07\n",
      "2018-12-12 16:54:21\n",
      "2018-12-12 17:01:39\n",
      "2018-12-12 17:02:07\n",
      "2018-12-12 17:04:15\n",
      "2018-12-12 19:00:41\n",
      "2018-12-12 19:13:29\n",
      "2018-12-12 19:18:51\n",
      "2018-12-12 19:55:13\n",
      "2018-12-12 20:06:31\n",
      "2018-12-12 20:28:57\n",
      "Total HTMGs = 72\n"
     ]
    }
   ],
   "source": [
    "## We now have RANDOM, EC, EOD, puffMarker\n",
    "## Still need to bring in the HTMGs.\n",
    "participant_id = 252\n",
    "delta = 9\n",
    "quit_iloc = np.where(participant_dates['participant'] == participant_id)\n",
    "quit_row = participant_dates.iloc[quit_iloc[0][0]]\n",
    "quit_time = datetime.datetime.strptime(quit_row['quit_date'], '%m/%d/%y')\n",
    "current_date = quit_time + timedelta(days=delta)\n",
    "print \"Quit date is %s\" % quit_time\n",
    "print \"Current date is %s\" % current_date\n",
    "\n",
    "eod_iloc = np.where(eod_complete['participant_id'] == participant_id)\n",
    "eod_rows = eod_complete.iloc[eod_iloc[0]]\n",
    "eod_rows = pd.DataFrame.from_dict(eod_rows)\n",
    "\n",
    "for irow in range(0,eod_rows.shape[0]):\n",
    "    row = eod_rows.iloc[irow]\n",
    "    date = row['date']\n",
    "    try:\n",
    "        time = datetime.datetime.strptime(date, '%m/%d/%Y %H:%M')\n",
    "    except:\n",
    "        time = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "    temp = time - current_date\n",
    "    if time.hour  == 0 or time.hour == 1:\n",
    "        continue\n",
    "    if temp.days == 0:\n",
    "        print eod_rows.iloc[irow]\n",
    "\n",
    "random_iloc = np.where(random_complete['participant_id'] == participant_id)\n",
    "random_rows = random_complete.iloc[random_iloc[0]]\n",
    "random_rows = pd.DataFrame(random_rows)\n",
    "print 'Onto RANDOM EMA'\n",
    "\n",
    "for irow in range(0,random_rows.shape[0]):\n",
    "    row = random_rows.iloc[irow]\n",
    "    date = row['date']\n",
    "    try:\n",
    "        time = datetime.datetime.strptime(date, '%m/%d/%Y %H:%M')\n",
    "    except:\n",
    "        time = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "    temp = time - current_date\n",
    "    if temp.days == 0:\n",
    "        print row['smoke'], row['when_smoke'], row['date']\n",
    "\n",
    "contingent_iloc = np.where(contingent_complete['participant_id'] == participant_id)\n",
    "contingent_rows = contingent_complete.iloc[contingent_iloc[0]]\n",
    "contingent_rows = pd.DataFrame(contingent_rows)\n",
    "print 'Onto Event Contingent EMA'\n",
    "\n",
    "for irow in range(0,contingent_rows.shape[0]):\n",
    "    row = contingent_rows.iloc[irow]\n",
    "    date = row['date']\n",
    "    try:\n",
    "        time = datetime.datetime.strptime(date, '%m/%d/%Y %H:%M')\n",
    "    except:\n",
    "        time = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "    temp = time - current_date\n",
    "    if temp.days == 0:\n",
    "        print row['smoke'], row['when_smoke'], row['date']\n",
    "\n",
    "puffmarker_episode_iloc = np.where(puffmarker_episode_complete['participant_id'] == participant_id)\n",
    "puffmarker_episode_rows = puffmarker_episode_complete.iloc[puffmarker_episode_iloc[0]]\n",
    "puffmarker_episode_rows = pd.DataFrame(puffmarker_episode_rows)\n",
    "print 'Onto puffMarker episode detection'\n",
    "\n",
    "for irow in range(0,puffmarker_episode_rows.shape[0]):\n",
    "    row = puffmarker_episode_rows.iloc[irow]\n",
    "    date = row['date']\n",
    "    try:\n",
    "        time = datetime.datetime.strptime(date, '%m/%d/%Y %H:%M')\n",
    "    except:\n",
    "        time = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "    temp = time - current_date\n",
    "    if temp.days == 0:\n",
    "        print row['date']\n",
    "\n",
    "puffmarker_iloc = np.where(puffmarker_complete['participant_id'] == participant_id)\n",
    "puffmarker_rows = puffmarker_complete.iloc[puffmarker_iloc[0]]\n",
    "puffmarker_rows = pd.DataFrame(puffmarker_rows)\n",
    "print 'Onto puffMarker puff detection'\n",
    "\n",
    "total = 0\n",
    "for irow in range(0,puffmarker_rows.shape[0]):\n",
    "    row = puffmarker_rows.iloc[irow]\n",
    "    date = row['date']\n",
    "    try:\n",
    "        time = datetime.datetime.strptime(date, '%m/%d/%Y %H:%M')\n",
    "    except:\n",
    "        time = datetime.datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "    temp = time - current_date\n",
    "    if temp.days == 0:\n",
    "        total += 1\n",
    "        print row['date']\n",
    "\n",
    "print \"Total HTMGs = %s\" %total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.238531809327319\n",
      "-7.742609206103594\n",
      "-140.1943037285996\n",
      "-141.40789381886782\n",
      "-0.52554\n",
      "0.4087639892967142\n",
      "0.00209274208234\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "smoking_rate = 1./4.5\n",
    "print 4*np.log(smoking_rate)-smoking_rate\n",
    "print 5*np.log(smoking_rate)-smoking_rate\n",
    "\n",
    "\n",
    "num_htmgs = 72\n",
    "lambda_parameter = 1/(3.5*6.)\n",
    "lambda_prime_hour = 1/(1.25*6.)\n",
    "window_lambda = lambda_parameter+lambda_prime_hour\n",
    "seq1 = [4., 4., 8.,3.,3.]\n",
    "remaining_htmgs1 = num_htmgs - np.sum(seq1)\n",
    "time_in_smoking1 = 1./6. * len(seq1)\n",
    "remaining_time1 = (20.5-7) - 1./6. * len(seq1)\n",
    "\n",
    "total1 = remaining_htmgs1*np.log(lambda_prime_hour) - lambda_prime_hour*remaining_time1\n",
    "total1 += np.sum(seq1)*np.log(window_lambda) - window_lambda*time_in_smoking1\n",
    "print total1\n",
    "\n",
    "seq2 = [4., 8.,3.,3.]\n",
    "remaining_htmgs2 = num_htmgs - np.sum(seq2)\n",
    "time_in_smoking2 = 1./6. * len(seq2)\n",
    "remaining_time2 = (20.5-7) - 1./6. * len(seq2)\n",
    "\n",
    "total2 = remaining_htmgs2*np.log(lambda_prime_hour) - lambda_prime_hour*remaining_time2\n",
    "total2 += np.sum(seq2)*np.log(window_lambda) - window_lambda*time_in_smoking2\n",
    "print total2\n",
    "\n",
    "temp = -5.29677-141.40789-3.6177 - (-6.54952-140.19430-3.0530)\n",
    "print temp\n",
    "print 1 - np.exp(temp)\n",
    "print temp - log(1-0.41)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
